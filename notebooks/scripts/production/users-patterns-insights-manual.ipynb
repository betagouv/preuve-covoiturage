{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "   Parameter name          Example Value                                            Description\n",
    "- `connection_string` : 'postgresql://postgres:postgres@localhost:5432/local'   -> Postgresql URL connection string\n",
    "- `aom_insee` :          '217500016'                                            -> Aom insee code representing geo perimeter to apply the algorithm\n",
    "- `start_date` :         '2023-02-28 23:59:59'                                  -> Start date\n",
    "- `end_date`:             '2023-04-30 00:00:01'                                 -> End date\n",
    "- `policy_id`             : 459                                                 -> Policy id filter on incentive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sqlalchemy import create_engine, text\n",
    "import networkx as nx\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "load_dotenv()\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "sys.path.append('/notebooks/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aom_insee = '217500016'\n",
    "start_date ='2023-02-28 23:59:59'\n",
    "end_date='2023-04-30 00:00:01'\n",
    "policy_id = 459\n",
    "\n",
    "DATABASE = os.environ['DATABASE']\n",
    "USER = os.environ['USER_DB']\n",
    "PASSWORD = os.environ['PASSWORD']\n",
    "PORT = os.environ['PORT']\n",
    "HOST = os.environ['HOST']\n",
    "\n",
    "engine = create_engine(f\"postgresql://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\",connect_args={'sslmode':'require'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedTable) missing FROM-clause entry for table \"pi\"\nLINE 7: CASE WHEN pi.result >= 0 THEN pi.result ELSE 0 END as incent...\n                  ^\n\n[SQL: SELECT cc._id, cc.is_driver, ci.phone_trunc, cc.datetime, cc.duration, cc.operator_id, cc.seats,\nST_AsText(cc.start_position) as start_wkt, ST_AsText(cc.end_position) as end_wkt, \ncc.operator_journey_id,\ncc.distance,\nci.operator_user_id,\ncc.end_position,\nCASE WHEN pi.result >= 0 THEN pi.result ELSE 0 END as incentive,\ncc.operator_trip_id,\n \ncc2.is_driver as other_is_driver,\nci2.phone_trunc as other_phone_trunc\nFROM CARPOOL.CARPOOLS cc\n   join carpool.identities ci on cc.identity_id = ci._id\n   join geo.perimeters gps on cc.start_geo_code = gps.arr and gps.year = 2022\n   join geo.perimeters gpe on cc.end_geo_code = gpe.arr and gpe.year = 2022\n   JOIN CARPOOL.CARPOOLS AS CC2 ON CC.OPERATOR_JOURNEY_ID = CC2.OPERATOR_JOURNEY_ID and CC.is_driver != cc2.is_driver\n   JOIN CARPOOL.IDENTITIES AS CI2 on CC2.IDENTITY_ID = CI2._id\n    WHERE CC.DATETIME >= '2023-06-01'::timestamp AT TIME ZONE 'EUROPE/PARIS'\n    AND CC.DATETIME < '2023-07-01'::timestamp AT TIME ZONE 'EUROPE/PARIS'\n    and (gps.aom = '217500016' or gpe.aom = '217500016' or gps.reg = '217500016' or gpe.reg = '217500016') and gps.year = 2022 and gpe.year = 2022\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1964\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1965\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1966\u001b[0m         )\n\u001b[1;32m   1968\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/default.py:748\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 748\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mUndefinedTable\u001b[0m: missing FROM-clause entry for table \"pi\"\nLINE 7: CASE WHEN pi.result >= 0 THEN pi.result ELSE 0 END as incent...\n                  ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m\n\u001b[1;32m      6\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mSELECT cc._id, cc.is_driver, ci.phone_trunc, cc.datetime, cc.duration, cc.operator_id, cc.seats,\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39mST_AsText(cc.start_position) as start_wkt, ST_AsText(cc.end_position) as end_wkt, \u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39mcc.operator_journey_id,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m    \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand (gps.aom = \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00maom_insee\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m or gpe.aom = \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00maom_insee\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m or gps.reg = \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00maom_insee\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m or gpe.reg = \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00maom_insee\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m) and gps.year = 2022 and gpe.year = 2022\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39maom_insee\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[39mwith\u001b[39;00m engine\u001b[39m.\u001b[39mconnect() \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m---> 29\u001b[0m     df_carpool \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql_query(text(query), conn)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/pandas/io/sql.py:397\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[39mparameter will be converted to UTC.\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    396\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con)\n\u001b[0;32m--> 397\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    398\u001b[0m     sql,\n\u001b[1;32m    399\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    400\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    401\u001b[0m     coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    402\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    403\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    404\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    405\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/pandas/io/sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[39mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \n\u001b[1;32m   1557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m args \u001b[39m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 1560\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1561\u001b[0m columns \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m   1563\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/pandas/io/sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1404\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1405\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnectable\u001b[39m.\u001b[39;49mexecution_options()\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1414\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1414\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[1;32m   1415\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1416\u001b[0m         distilled_parameters,\n\u001b[1;32m   1417\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[1;32m   1418\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:486\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    485\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, Executable)\n\u001b[0;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[1;32m    487\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[1;32m    488\u001b[0m     )\n\u001b[1;32m    489\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1638\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1626\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1627\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1628\u001b[0m )\n\u001b[1;32m   1630\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1631\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1632\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1637\u001b[0m )\n\u001b[0;32m-> 1638\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1639\u001b[0m     dialect,\n\u001b[1;32m   1640\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[1;32m   1641\u001b[0m     compiled_sql,\n\u001b[1;32m   1642\u001b[0m     distilled_parameters,\n\u001b[1;32m   1643\u001b[0m     execution_options,\n\u001b[1;32m   1644\u001b[0m     compiled_sql,\n\u001b[1;32m   1645\u001b[0m     distilled_parameters,\n\u001b[1;32m   1646\u001b[0m     elem,\n\u001b[1;32m   1647\u001b[0m     extracted_params,\n\u001b[1;32m   1648\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[1;32m   1649\u001b[0m )\n\u001b[1;32m   1650\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1652\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1653\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1657\u001b[0m         ret,\n\u001b[1;32m   1658\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1842\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1838\u001b[0m         dialect,\n\u001b[1;32m   1839\u001b[0m         context,\n\u001b[1;32m   1840\u001b[0m     )\n\u001b[1;32m   1841\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[1;32m   1843\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1844\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1983\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1980\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1982\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1983\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1984\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1985\u001b[0m     )\n\u001b[1;32m   1987\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2326\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2324\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2325\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2326\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   2327\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2328\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1962\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1964\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1965\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1966\u001b[0m         )\n\u001b[1;32m   1968\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1970\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1971\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1975\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1976\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RPC_fraud_detection-QRnsHc7R/lib/python3.10/site-packages/sqlalchemy/engine/default.py:748\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 748\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.errors.UndefinedTable) missing FROM-clause entry for table \"pi\"\nLINE 7: CASE WHEN pi.result >= 0 THEN pi.result ELSE 0 END as incent...\n                  ^\n\n[SQL: SELECT cc._id, cc.is_driver, ci.phone_trunc, cc.datetime, cc.duration, cc.operator_id, cc.seats,\nST_AsText(cc.start_position) as start_wkt, ST_AsText(cc.end_position) as end_wkt, \ncc.operator_journey_id,\ncc.distance,\nci.operator_user_id,\ncc.end_position,\nCASE WHEN pi.result >= 0 THEN pi.result ELSE 0 END as incentive,\ncc.operator_trip_id,\n \ncc2.is_driver as other_is_driver,\nci2.phone_trunc as other_phone_trunc\nFROM CARPOOL.CARPOOLS cc\n   join carpool.identities ci on cc.identity_id = ci._id\n   join geo.perimeters gps on cc.start_geo_code = gps.arr and gps.year = 2022\n   join geo.perimeters gpe on cc.end_geo_code = gpe.arr and gpe.year = 2022\n   JOIN CARPOOL.CARPOOLS AS CC2 ON CC.OPERATOR_JOURNEY_ID = CC2.OPERATOR_JOURNEY_ID and CC.is_driver != cc2.is_driver\n   JOIN CARPOOL.IDENTITIES AS CI2 on CC2.IDENTITY_ID = CI2._id\n    WHERE CC.DATETIME >= '2023-06-01'::timestamp AT TIME ZONE 'EUROPE/PARIS'\n    AND CC.DATETIME < '2023-07-01'::timestamp AT TIME ZONE 'EUROPE/PARIS'\n    and (gps.aom = '217500016' or gpe.aom = '217500016' or gps.reg = '217500016' or gpe.reg = '217500016') and gps.year = 2022 and gpe.year = 2022\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "start_date = (now.replace(day=1) - datetime.timedelta(days=1)).replace(day=1).strftime('%Y-%m-%d')\n",
    "end_date = now.replace(day=1).strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "query = f\"\"\"SELECT cc._id, cc.is_driver, ci.phone_trunc, cc.datetime, cc.duration, cc.operator_id, cc.seats,\n",
    "ST_AsText(cc.start_position) as start_wkt, ST_AsText(cc.end_position) as end_wkt, \n",
    "cc.operator_journey_id,\n",
    "cc.distance,\n",
    "ci.operator_user_id,\n",
    "cc.end_position,\n",
    "CASE WHEN pi.result >= 0 THEN pi.result ELSE 0 END as incentive,\n",
    "cc.operator_trip_id,\n",
    " \n",
    "cc2.is_driver as other_is_driver,\n",
    "ci2.phone_trunc as other_phone_trunc\n",
    "FROM CARPOOL.CARPOOLS cc\n",
    "   join carpool.identities ci on cc.identity_id = ci._id\n",
    "   join geo.perimeters gps on cc.start_geo_code = gps.arr and gps.year = 2022\n",
    "   join geo.perimeters gpe on cc.end_geo_code = gpe.arr and gpe.year = 2022\n",
    "   LEFT JOIN policy.incentives pi on pi.carpool_id = cc._id and pi.policy_id = '{policy_id}'\n",
    "   JOIN CARPOOL.CARPOOLS AS CC2 ON CC.OPERATOR_JOURNEY_ID = CC2.OPERATOR_JOURNEY_ID and CC.is_driver != cc2.is_driver\n",
    "   JOIN CARPOOL.IDENTITIES AS CI2 on CC2.IDENTITY_ID = CI2._id\n",
    "    WHERE CC.DATETIME >= '{start_date}'::timestamp AT TIME ZONE 'EUROPE/PARIS'\n",
    "    AND CC.DATETIME < '{end_date}'::timestamp AT TIME ZONE 'EUROPE/PARIS'\n",
    "    {f\"and (gps.aom = '{aom_insee}' or gpe.aom = '{aom_insee}' or gps.reg = '{aom_insee}' or gpe.reg = '{aom_insee}') and gps.year = 2022 and gpe.year = 2022\" if aom_insee else \"\"}\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_carpool = pd.read_sql_query(text(query), conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1 \n",
    "Conversion des des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carpool['datetime'] = pd.to_datetime(df_carpool['datetime'])\n",
    "df_carpool['day'] = df_carpool['datetime'].dt.date\n",
    "df_carpool['incentive'] = df_carpool['incentive']/100\n",
    "df_carpool['duration'] = np.round(df_carpool['duration']/60)\n",
    "df_carpool['distance'] = np.round(df_carpool['distance']/1000,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 2\n",
    "\n",
    "Création de fonctions pour le calcul de changement de rôle par jours etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_day_change_count(row):\n",
    "    if len(row['roles']) <= 1:\n",
    "        return 0\n",
    "    count = sum((row['roles'][i] != row['roles'][i+1]) for i in range(len(row['roles']) - 1) if row['carpool_day_list'][i] == row['carpool_day_list'][i+1])\n",
    "    return count\n",
    "\n",
    "def total_change_count(row):\n",
    "    if len(row['roles']) <= 1:\n",
    "        return 0\n",
    "    count = sum((row['roles'][i] != row['roles'][i+1]) for i in range(len(row['roles']) - 1))\n",
    "    return count\n",
    "\n",
    "def intra_day_change_percentage(row):\n",
    "    unique_days = np.unique(row['carpool_day_list'])\n",
    "    count = sum(1 for day in unique_days if any((row['roles'][i] != row['roles'][i+1]) for i in range(len(row['roles']) - 1) if row['carpool_day_list'][i] == day and row['carpool_day_list'][i+1] == day))\n",
    "    percentage = np.round(count / len(unique_days) * 100, 2)\n",
    "    return percentage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 3 \n",
    "Calcul des indicateurs par phone_trunc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_trunc_insights_df = df_carpool.groupby('phone_trunc').agg({\n",
    "    'datetime': ['min', 'max'],\n",
    "    'duration':  ['mean', 'count'],\n",
    "    'distance': 'mean',\n",
    "    'incentive': 'sum',\n",
    "    'is_driver': ['mean',list],\n",
    "    'day': ['nunique', list],\n",
    "    'operator_journey_id': [list],\n",
    "    'operator_id': [list]\n",
    "})\n",
    "\n",
    "phone_trunc_insights_df.columns = ['departure_date',\n",
    "                                   'end_date',\n",
    "                                   'average_duration',\n",
    "                                   'num_trips',\n",
    "                                   'average_distance',\n",
    "                                   'total_incentives',\n",
    "                                   'driver_trip_percentage',\n",
    "                                   'roles',\n",
    "                                   'carpool_days',\n",
    "                                   'carpool_day_list',\n",
    "                                   'trip_id_list',\n",
    "                                   'operator_list']\n",
    "\n",
    "phone_trunc_insights_df.reset_index(inplace=True)\n",
    "\n",
    "phone_trunc_insights_df['num_days'] = (phone_trunc_insights_df['end_date'].dt.date - phone_trunc_insights_df['departure_date'].dt.date).dt.days\n",
    "phone_trunc_insights_df['average_trip_count'] = phone_trunc_insights_df.apply(\n",
    "    lambda row: row['num_trips'] / row['carpool_days'] if row['carpool_days'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "phone_trunc_insights_df['driver_trip_percentage'] = np.round(phone_trunc_insights_df['driver_trip_percentage'] * 100,2)\n",
    "\n",
    "\n",
    "phone_trunc_insights_df['num_operators'] = phone_trunc_insights_df['operator_list'].apply(lambda row: len(np.unique(row)))\n",
    "phone_trunc_insights_df['role_change'] = phone_trunc_insights_df['roles'].apply(lambda x: len(np.unique(x)) > 1)\n",
    "\n",
    "\n",
    "\n",
    "phone_trunc_insights_df['intraday_change_count'] = phone_trunc_insights_df.apply(intra_day_change_count, axis=1)\n",
    "phone_trunc_insights_df['total_change_count'] = phone_trunc_insights_df.apply(total_change_count, axis=1)\n",
    "\n",
    "\n",
    "phone_trunc_insights_df['intraday_change_percentage'] = phone_trunc_insights_df.apply(intra_day_change_percentage, axis=1)\n",
    "\n",
    "phone_trunc_insights_df['total_change_percentage'] = phone_trunc_insights_df.apply(lambda row: np.round(row['total_change_count'] / len(row['operator_list']) * 100, 2), axis=1)\n",
    "phone_trunc_insights_df = phone_trunc_insights_df[['phone_trunc', 'departure_date', 'end_date', 'num_days', 'average_duration',\n",
    "                                                   'average_distance', 'total_incentives','average_trip_count' ,'num_operators',\n",
    "                                                   'driver_trip_percentage',\n",
    "                                                   'role_change', 'intraday_change_count',\n",
    "                                                   'total_change_count', 'intraday_change_percentage',\n",
    "                                                   'total_change_percentage', 'carpool_days',\n",
    "                                                   'carpool_day_list', 'trip_id_list', 'operator_list']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 4\n",
    "\n",
    "Ajout dans la bd des insights par phone trunc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_do_nothing_on_conflict(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_conflict_do_nothing(index_elements=['phone_trunc', 'departure_date', 'end_date'])\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "    \n",
    "phone_trunc_insights_df.to_sql(\n",
    "    name=\"phone_insights\",\n",
    "    schema=\"fraudcheck\",\n",
    "    con=engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=insert_or_do_nothing_on_conflict\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 5\n",
    "Appliquer la détection de fraude triangulaire sur les données calculées phone_trunc_insights_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la liste des phone_trunc\n",
    "phone_numbers = phone_trunc_insights_df.phone_trunc.to_list()\n",
    "\n",
    "# filtrer les trajets potentiellement frauduleux\n",
    "potential_fraud_carpool_df = df_carpool[df_carpool['phone_trunc'].isin(phone_numbers)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des insight des phone trunc à chaque trajet\n",
    "potential_fraud_carpool_with_insights_df = potential_fraud_carpool_df.merge(phone_trunc_insights_df,how='left',on='phone_trunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouper les information par trajets\n",
    "filtered_df_grouped = potential_fraud_carpool_with_insights_df.groupby(['operator_journey_id']).agg({'phone_trunc' : list,\n",
    "                                                                                                     'intraday_change_percentage': list,\n",
    "                                                                                                     'intraday_change_count' : list,\n",
    "                                                                                                     'role_change' : list,\n",
    "                                                                                                     'total_change_percentage' : list})\n",
    "filtered_df_grouped.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirer les trajets ou les paricipany n'ont jamais cha,gé de rôles\n",
    "filtered_df_grouped = filtered_df_grouped[filtered_df_grouped['role_change'].apply(lambda x: x != [False, False])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithme de création de groupe frauduleux \n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges between connected phone trunc\n",
    "for _, row in filtered_df_grouped.iterrows():\n",
    "    phone_list = row['phone_trunc']\n",
    "    for i in range(len(phone_list) - 1):\n",
    "        for j in range(i + 1, len(phone_list)):\n",
    "            if G.has_edge(phone_list[i], phone_list[j]):\n",
    "                G[phone_list[i]][phone_list[j]]['interactions'] += 1\n",
    "            else:\n",
    "                G.add_edge(phone_list[i], phone_list[j], interactions=1)\n",
    "\n",
    "# Find connected components in the graph\n",
    "#connected_components = [component for component in nx.connected_components(G) if len(component) > 2]\n",
    "connected_components = nx.connected_components(G)\n",
    "\n",
    "# Create DataFrame with groups\n",
    "group_data = []\n",
    "group_degree_centrality = []\n",
    "group_betweenness_centrality = []\n",
    "\n",
    "for idx, component in enumerate(connected_components):\n",
    "    group_graph = G.subgraph(component)\n",
    "    degree_centrality = nx.degree_centrality(group_graph)\n",
    "    betweenness_centrality = nx.betweenness_centrality(group_graph)\n",
    "    group_phones = list(component)\n",
    "    group_journeys = df_carpool[df_carpool['phone_trunc'].isin(group_phones)]\n",
    "    group_journeys = group_journeys.drop_duplicates('operator_journey_id').copy()\n",
    "    group_journeys = potential_fraud_carpool_with_insights_df[potential_fraud_carpool_with_insights_df['phone_trunc'].isin(group_phones)].copy()\n",
    "    group_duration = np.round(group_journeys['duration'].mean())\n",
    "    group_operator_id = group_journeys['operator_journey_id'].copy()\n",
    "    group_journeys['date'] = group_journeys['datetime'].dt.date.copy()\n",
    "    grouped = group_journeys.groupby('phone_trunc').size().reset_index(name='count')\n",
    "    total_change_percentage = np.unique(group_journeys['total_change_percentage'].to_list())\n",
    "    \n",
    "    group_data.append({\n",
    "        'group': idx+1,\n",
    "        'phone_trunc': group_phones,\n",
    "        'num_participants': len(group_phones),\n",
    "        'num_trips': len(group_journeys.operator_journey_id.unique()),\n",
    "        'operator_list' : group_journeys.operator_id.unique(),\n",
    "        'num_operators' : len(group_journeys.operator_id.unique()),\n",
    "        'average_duration': group_duration,\n",
    "        'departure_date': group_journeys['datetime'].min().date(),\n",
    "        'end_date': group_journeys['datetime'].max().date(),\n",
    "        'average_daily_trips' : np.round(group_journeys.drop_duplicates('operator_journey_id')['datetime'].dt.date.value_counts().sort_index().mean()),\n",
    "        #'daily_mean_trips' : grouped.loc[grouped['count'].idxmax(),'count']/len(group_journeys.groupby('date')),\n",
    "        'total_change_percentage' : total_change_percentage,\n",
    "        'total_incentives' : np.sum(group_journeys.drop_duplicates('operator_journey_id')['incentive']*100),\n",
    "        'central_participants' : degree_centrality,\n",
    "        'intermediate_participants' : betweenness_centrality,\n",
    "        'journey_id_list' : group_operator_id,\n",
    "      \n",
    "    })\n",
    "groups_df = pd.DataFrame(group_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 6\n",
    "\n",
    "Ajout dans la bd les groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insert_or_do_nothing_on_conflict(table, conn, keys, data_iter):\n",
    "    insert_stmt = insert(table.table).values(list(data_iter))\n",
    "    on_duplicate_key_stmt = insert_stmt.on_conflict_do_nothing(index_elements=['id', 'group', 'phone_trunc'])\n",
    "    conn.execute(on_duplicate_key_stmt)\n",
    "\n",
    "groups_df.to_sql(\n",
    "    name=\"potential_triangular_patterns\",\n",
    "    schema=\"fraudcheck\",\n",
    "    con=engine,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    method=insert_or_do_nothing_on_conflict\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
