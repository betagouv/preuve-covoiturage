{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de la fraude triangulaire dans les données de trajets de covoiturage\n",
    "\n",
    "[Introduction](#introduction)\n",
    "  - Présentation du contexte et de l'objectif de l'analyse\n",
    "  - Explication des données de trajets de covoiturage utilisées\n",
    "  \n",
    "[Chargement des données](#data)\n",
    " - Importation des bibliothèques nécessaires\n",
    " - Chargement des données de l'AOM et de la période spécifiées\n",
    "\n",
    "[Détection des paires de changement de rôle](#pairs)\n",
    "  - Création d'une fonction pour rechercher les paires de participants qui changent de rôle dans les trajets\n",
    "  - Application de la fonction aux données de trajets pour identifier les paires suspectes\n",
    "\n",
    "[Analyse des groupes frauduleux avec les graphes de connexion](#groups)\n",
    "  - Création d'un graphe de connexion à partir des groupes suspects\n",
    "  - Identification des groupes de participants frauduleux à l'aide des composantes connexes du graphe\n",
    "  - Calcul des mesures de centralité pour évaluer l'importance des participants dans les groupes\n",
    "\n",
    "[Rapport sur les groupes frauduleux détectés](#report)\n",
    " - Présentation des groupes frauduleux identifiés avec leurs caractéristiques (nombre de participants, durée des trajets, etc.)\n",
    " - Statistiques descriptives sur les groupes (nombre moyen de participants, durée moyenne des trajets, etc.)\n",
    "\n",
    "[Conclusion](#conclusions)\n",
    " - Récapitulatif des principales conclusions de l'analyse\n",
    " - Discussion sur les implications et les recommandations éventuelles\n",
    "\n",
    "## [Introduction](#introduction)\n",
    "### Présentation du contexte et de l'objectif de l'analyse\n",
    "\n",
    "Dans le cadre de cette analyse, nous nous intéressons aux données de trajets de covoiturage. Le covoiturage est devenu une alternative populaire pour les déplacements, offrant un moyen économique et écologique de se déplacer d'un endroit à un autre. Cependant, comme toute activité impliquant des interactions entre individus, il peut également être sujet à des comportements frauduleux.\n",
    "\n",
    "L'objectif de cette analyse est de détecter les groupes de participants impliqués dans des activités frauduleuses dans les trajets de covoiturage. Nous cherchons à identifier les participants qui changent de rôle de manière suspecte, c'est-à-dire ceux qui passent de conducteur à passager ou vice versa de manière répétée et inhabituelle. En détectant ces paires de participants, nous pouvons explorer les connexions entre eux pour identifier les groupes frauduleux et en comprendre les schémas de comportement.\n",
    "\n",
    "### Explication des données de trajets de covoiturage utilisées\n",
    "\n",
    "Les données de trajets de covoiturage utilisées dans cette analyse comprennent des informations sur les trajets effectués dans une région spécifique pendant une période donnée. Chaque trajet est caractérisé par des détails tels que l'identifiant du trajet, la durée, la date et l'heure, l'identifiant de l'opérateur, l'identifiant du trajet ainsi que les numéros de téléphone tronqués des participants.\n",
    "\n",
    "Ces données nous permettent de reconstituer les trajets effectués par les participants et d'analyser les interactions entre eux. En nous concentrant sur les changements de rôle suspects, nous pouvons détecter les groupes de participants qui pourraient être impliqués dans des activités frauduleuses.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Chargement des données](#data)\n",
    "### Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import ast\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données de l'AOM et de la période spécifiées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2023-02-27 23:59:59\"\n",
    "end_date = \"2023-04-30 00:00:01\"\n",
    "aom_insee = \"217500016\"\n",
    "\n",
    "DATABASE = os.environ['DATABASE']\n",
    "USER = os.environ['USER_DB']\n",
    "PASSWORD = os.environ['PASSWORD']\n",
    "PORT = os.environ['PORT']\n",
    "con = psycopg2.connect(\n",
    "    host=os.environ['HOST'],\n",
    "    database=DATABASE,\n",
    "    user=USER,\n",
    "    password=PASSWORD,\n",
    "    port=PORT,\n",
    "    sslmode=\"require\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"SELECT cc._id, cc.is_driver, ci.phone_trunc, cc.datetime, cc.duration, cc.operator_id, cc.start_position, cc.operator_journey_id,cc.start_geo_code,cc.end_geo_code,\n",
    "cc.end_position, gmap_url(cc.start_position, cc.end_position), CASE WHEN cc.is_driver THEN pa.rpc_driver_uuid ELSE pa.rpc_passenger_uuid END as rpc_uuid, pi.result\n",
    "FROM CARPOOL.CARPOOLS cc\n",
    "   join carpool.identities ci on cc.identity_id = ci._id\n",
    "   join geo.perimeters gps on cc.start_geo_code = gps.arr and gps.year = 2022\n",
    "   join geo.perimeters gpe on cc.end_geo_code = gpe.arr and gpe.year = 2022\n",
    "   LEFT join phones.all pa on pa.operator_journey_id = cc.operator_journey_id\n",
    "   LEFT JOIN policy.incentives pi on pi.carpool_id = cc._id and pi.policy_id = 459\n",
    "WHERE CC.DATETIME >= '{start_date}'::timestamp AT TIME ZONE 'EUROPE/PARIS'\n",
    "    AND cc.operator_id IN (3,4,9)\n",
    "\tAND CC.DATETIME < '{end_date}'::timestamp AT TIME ZONE 'EUROPE/PARIS'\n",
    "    {f\"and (gps.aom = '{aom_insee}' or gpe.aom = '{aom_insee}') and gps.year = 2022 and gpe.year = 2022\" if aom_insee else \"\"}\n",
    "\"\"\"\n",
    "df_carpool = pd.read_sql(query, con)\n",
    "df_carpool.head(10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carpool.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carpool.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Détection des paires de changement de rôle](pairs)\n",
    "### Création d'une fonction pour rechercher les paires de participants qui changent de rôle dans les trajets\n",
    "\n",
    "#### Méthdodologie :\n",
    " - Ajouter colonne conducteur ou passager en fonction de 'is_driver'.\n",
    " - Création variable unique phone_trunc avec rôle (conducteur ou passager).\n",
    " - Enumérer la liste des uniques phone_trunc avec rôle pour chaque operator_journey_id.\n",
    " - Aggréger par pair de phone_trunc.\n",
    " - Filtrer les pairs de phone_trunc qui ont une liste de rôle unique de taille plus grande que 2 = changement de rôle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_potential_triangular_pairs(df):   \n",
    "    get_role = lambda x: 'driver' if x else 'passenger'\n",
    "    df['role'] = df['is_driver'].apply(get_role)\n",
    "    df['temp'] = df['phone_trunc'] +'_'+ df['role']\n",
    "    _temp = df.groupby('operator_journey_id').agg(lambda x: sorted(list(x))).reset_index()\n",
    "    _temp['phone_trunc'] = _temp['phone_trunc'].astype(str)\n",
    "    grouped = _temp.groupby('phone_trunc')[['temp','operator_journey_id']].agg(lambda x: list(x)).reset_index()\n",
    "    _temp_1 = pd.DataFrame(grouped['temp'].explode().explode())\n",
    "    _temp_1.reset_index(inplace=True)\n",
    "    _temp_1.groupby('index').agg({'temp' : 'nunique'}).reset_index().temp\n",
    "    grouped['roles_list'] = _temp_1.groupby('index').agg({'temp' : 'nunique'}).reset_index().temp\n",
    "    potential_triangular = lambda x: True if x > 2 else False\n",
    "    grouped['potential_triangular'] = grouped.roles_list.apply(potential_triangular)\n",
    "\n",
    "    return grouped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de la fonction aux données de trajets pour identifier les paires suspectes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangular_df = find_potential_triangular_pairs(df_carpool)\n",
    "triangular_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % de trajets potentiellement triangulaire\n",
    "len(triangular_df[triangular_df.potential_triangular == True])/len(triangular_df)*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Analyse des groupes frauduleux avec les graphes de connexion](#groups)\n",
    "\n",
    "### Création d'un graphe de connexion à partir des groupes suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrer df_carpool sur les phone_trunc potentiel à la fraude triangulaire\n",
    "phone_numbers = triangular_df[triangular_df.potential_triangular ==  True]['phone_trunc'].to_list()\n",
    "phone_truncs = []\n",
    "for item in phone_numbers:\n",
    "    numbers = ast.literal_eval(item)\n",
    "    phone_truncs.extend(numbers)\n",
    "    # Filter the original dataset based on phone truncs\n",
    "filtered_df = df_carpool[df_carpool['phone_trunc'].isin(phone_truncs)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# petite vérif\n",
    "set(filtered_df.phone_trunc.unique()) == set(np.unique(phone_truncs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_grouped = filtered_df.groupby(['operator_journey_id','duration','datetime','operator_id']).agg({'phone_trunc' : list })\n",
    "filtered_df_grouped.reset_index(inplace=True)\n",
    "filtered_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph for only the potential triangular for pairs\n",
    "G = nx.Graph()\n",
    "# Add edges between connected phone trunc\n",
    "for _, row in filtered_df_grouped.iterrows():\n",
    "    phone_list = row['phone_trunc']#.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")\n",
    "    for i in range(len(phone_list) - 1):\n",
    "        for j in range(i + 1, len(phone_list)):\n",
    "            G.add_edge(phone_list[i], phone_list[j])\n",
    "\n",
    "# Find connected components in the graph\n",
    "connected_components = [component for component in nx.connected_components(G) if len(component) == 2]\n",
    "\n",
    "# Visualize the groups\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Draw nodes and edges\n",
    "for component in connected_components:\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=list(component), node_size=200, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=list(G.subgraph(component).edges()), width=1.5, alpha=0.5)\n",
    "\n",
    "# Customize plot appearance\n",
    "plt.axis('off')\n",
    "plt.title('Fraudulent Pairs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph for only the potential triangular for pairs\n",
    "G = nx.Graph()\n",
    "# Add edges between connected phone trunc\n",
    "for _, row in filtered_df_grouped.iterrows():\n",
    "    phone_list = row['phone_trunc']#.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")\n",
    "    for i in range(len(phone_list) - 1):\n",
    "        for j in range(i + 1, len(phone_list)):\n",
    "            G.add_edge(phone_list[i], phone_list[j])\n",
    "\n",
    "# Find connected components in the graph\n",
    "connected_components = [component for component in nx.connected_components(G) if len(component) > 2]\n",
    "\n",
    "# Visualize the groups\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Draw nodes and edges\n",
    "for component in connected_components:\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=list(component), node_size=200, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=list(G.subgraph(component).edges()), width=1.5, alpha=0.5)\n",
    "\n",
    "# Customize plot appearance\n",
    "plt.axis('off')\n",
    "plt.title('Fraudulent Groups (more than 2)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph for only the potential triangular for pairs\n",
    "G = nx.Graph()\n",
    "# Add edges between connected phone trunc\n",
    "for _, row in filtered_df_grouped.iterrows():\n",
    "    phone_list = row['phone_trunc']#.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")\n",
    "    for i in range(len(phone_list) - 1):\n",
    "        for j in range(i + 1, len(phone_list)):\n",
    "            G.add_edge(phone_list[i], phone_list[j])\n",
    "\n",
    "# Find connected components in the graph\n",
    "connected_components = [component for component in nx.connected_components(G) if len(component) > 4]\n",
    "\n",
    "# Visualize the groups\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Draw nodes and edges\n",
    "for component in connected_components:\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=list(component), node_size=200, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=list(G.subgraph(component).edges()), width=1.5, alpha=0.5)\n",
    "\n",
    "# Customize plot appearance\n",
    "plt.axis('off')\n",
    "plt.title('Fraudulent Groups (more than 4)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# Add edges between connected phone trunc\n",
    "for _, row in filtered_df_grouped.iterrows():\n",
    "    phone_list = row['phone_trunc']\n",
    "    for i in range(len(phone_list) - 1):\n",
    "        for j in range(i + 1, len(phone_list)):\n",
    "            if G.has_edge(phone_list[i], phone_list[j]):\n",
    "                G[phone_list[i]][phone_list[j]]['interactions'] += 1\n",
    "            else:\n",
    "                G.add_edge(phone_list[i], phone_list[j], interactions=1)\n",
    "\n",
    "# Find connected components in the graph\n",
    "connected_components = [component for component in nx.connected_components(G) if len(component) > 20]\n",
    "\n",
    "# Visualize the groups\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42, k=0.1)\n",
    "\n",
    "# Calculate line widths based on interactions\n",
    "edge_widths = [0.5 * G[u][v]['interactions'] for u, v in G.edges()]\n",
    "\n",
    "# Draw nodes and edges\n",
    "for component in connected_components:\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=list(component), node_size=100, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=list(G.subgraph(component).edges()), width=edge_widths, alpha=0.5)\n",
    "\n",
    "# Add labels to nodes\n",
    "labels = {node: node for node in G.nodes() if node in connected_components}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=10, font_color='white')\n",
    "\n",
    "# Customize plot appearance\n",
    "plt.axis('off')\n",
    "plt.title('Fraudulent Groups (more than twenty)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Rapport sur les groupes frauduleux détectés](#report)\n",
    "\n",
    "### Présentation des groupes frauduleux identifiés avec leurs caractéristiques (nombre de participants, durée des trajets, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# Add edges between connected phone trunc\n",
    "for _, row in filtered_df_grouped.iterrows():\n",
    "    phone_list = row['phone_trunc']\n",
    "    for i in range(len(phone_list) - 1):\n",
    "        for j in range(i + 1, len(phone_list)):\n",
    "            if G.has_edge(phone_list[i], phone_list[j]):\n",
    "                G[phone_list[i]][phone_list[j]]['interactions'] += 1\n",
    "            else:\n",
    "                G.add_edge(phone_list[i], phone_list[j], interactions=1)\n",
    "\n",
    "# Find connected components in the graph\n",
    "#connected_components = [component for component in nx.connected_components(G) if len(component) > 2]\n",
    "connected_components = nx.connected_components(G)\n",
    "\n",
    "# Create DataFrame with groups\n",
    "group_data = []\n",
    "group_degree_centrality = []\n",
    "group_betweenness_centrality = []\n",
    "\n",
    "for idx, component in enumerate(connected_components):\n",
    "    group_graph = G.subgraph(component)\n",
    "    degree_centrality = nx.degree_centrality(group_graph)\n",
    "    betweenness_centrality = nx.betweenness_centrality(group_graph)\n",
    "\n",
    "    group_phones = list(component)\n",
    "    \n",
    "    group_journeys = df_carpool[df_carpool['phone_trunc'].isin(group_phones)]\n",
    "    group_duration = group_journeys['duration'].mean()//60\n",
    "    group_operator_id = group_journeys['operator_journey_id']\n",
    "    group_incentives = group_journeys['result']\n",
    "    group_start_date = group_journeys['datetime'].min().date()\n",
    "    group_end_date = group_journeys['datetime'].max().date()\n",
    "    group_journeys['date'] = group_journeys['datetime'].dt.date\n",
    "    grouped = group_journeys.groupby('phone_trunc').size().reset_index(name='count')\n",
    "    \n",
    "    group_data.append({\n",
    "        'Group': idx+1,\n",
    "        'Phone Numbers': group_phones,\n",
    "        'Phone Trunc Count': len(group_phones),\n",
    "        'Journeys Count': len(group_journeys.operator_journey_id.unique()),\n",
    "        'Operator Id' : group_journeys.operator_id.unique(),\n",
    "        'Number of Operator Id' : len(group_journeys.operator_id.unique()),\n",
    "        'Mean duration (min)': group_duration,\n",
    "        'Start Date': group_start_date,\n",
    "        'End Date': group_end_date,\n",
    "        'Daily mean trips' : group_journeys.drop_duplicates('operator_journey_id')['datetime'].dt.date.value_counts().sort_index().mean(),\n",
    "        'Participant(s) central' : degree_centrality,\n",
    "        'Participant(s) intermédiare' : betweenness_centrality,\n",
    "        'operator_journey_id' : group_operator_id,\n",
    "        'incentives' : group_incentives,\n",
    "        'id_max_occurence': grouped.loc[grouped['count'].idxmax(),'phone_trunc'],\n",
    "        'mean_per_day_id_max_occurence' : grouped.loc[grouped['count'].idxmax(),'count']/len(group_journeys.groupby('date'))\n",
    "      \n",
    "    })\n",
    "\n",
    "groups_df = pd.DataFrame(group_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "groups_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups_df.to_csv('./fraude_triangulaire_agg.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_phone_trunc_3 = groups_df[groups_df['mean_per_day_id_max_occurence']>= 3]['Phone Numbers'].explode()\n",
    "raude_triangulaire_3_journey_id_list = groups_df[groups_df['mean_per_day_id_max_occurence']>= 3]['operator_journey_id'].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df[groups_df['mean_per_day_id_max_occurence']>= 3]['operator_journey_id'].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraude_triangulaire_3_journey_id_df= df_carpool[df_carpool.operator_journey_id.isin(fraude_triangulaire_3_journey_id_list)]\n",
    "fraude_triangulaire_3_journey_id_df = fraude_triangulaire_3_journey_id_df.drop_duplicates('operator_journey_id').copy()\n",
    "#fraude_triangulaire_3_journey_id_df.to_csv('fraude_triangulaire_3_journey_id.csv',sep=';',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistiques descriptives sur les groupes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df['Operator Id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.sort_values('Daily mean trips',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df['mean_per_person'] = groups_df['Daily mean trips']/groups_df['Phone Trunc Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.sort_values('mean_per_person',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = groups_df[groups_df.mean_per_person >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort_values('Phone Trunc Count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get the group with the highest Journeys Count\n",
    "group_max_journeys = groups_df[groups_df['Journeys Count'] == groups_df['Journeys Count'].max()]\n",
    "\n",
    "# Get the relevant data for radar plot\n",
    "labels = ['Phone Trunc Count', 'Number of Operator Id', 'Daily Mean Trips']\n",
    "values = group_max_journeys[['Phone Trunc Count','Number of Operator Id', 'Daily mean trips']].values.flatten()\n",
    "\n",
    "# Perform Min-Max scaling on the values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "values_scaled = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "\n",
    "# Extend the scaled values array to match the length of labels\n",
    "values_scaled = np.append(values_scaled, values_scaled[0])\n",
    "\n",
    "# Calculate the angle for each axis\n",
    "angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "# Create the radar plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(polar=True))\n",
    "ax.fill(angles, values_scaled, color='skyblue', alpha=0.5)\n",
    "ax.plot(angles, values_scaled, color='blue', linewidth=1.5)\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "# Add a title\n",
    "plt.title('Radar Plot - Group with Highest Journeys Count', fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RPC_fraud_detection-QRnsHc7R",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
